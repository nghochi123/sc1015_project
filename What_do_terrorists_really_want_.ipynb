{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UBofCNpT6Th",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# What do terrorists really want?\n",
    "Google Collab [1/4] - https://colab.research.google.com/drive/1599wFpPYiRBZvVURqFiYF0_ivEbWPZZo?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mel_ng/OneDrive - Nanyang Technological University/NTU/Sem1.2/SC1015 (Introduction To Data Science & Artificial Intelligence)/Mini-Project/sc1015_project/What_do_terrorists_really_want_.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mel_ng/OneDrive%20-%20Nanyang%20Technological%20University/NTU/Sem1.2/SC1015%20%28Introduction%20To%20Data%20Science%20%26%20Artificial%20Intelligence%29/Mini-Project/sc1015_project/What_do_terrorists_really_want_.ipynb#ch0000110?line=0'>1</a>\u001b[0m \u001b[39m# Importing necessary libraries\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mel_ng/OneDrive%20-%20Nanyang%20Technological%20University/NTU/Sem1.2/SC1015%20%28Introduction%20To%20Data%20Science%20%26%20Artificial%20Intelligence%29/Mini-Project/sc1015_project/What_do_terrorists_really_want_.ipynb#ch0000110?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mel_ng/OneDrive%20-%20Nanyang%20Technological%20University/NTU/Sem1.2/SC1015%20%28Introduction%20To%20Data%20Science%20%26%20Artificial%20Intelligence%29/Mini-Project/sc1015_project/What_do_terrorists_really_want_.ipynb#ch0000110?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mel_ng/OneDrive%20-%20Nanyang%20Technological%20University/NTU/Sem1.2/SC1015%20%28Introduction%20To%20Data%20Science%20%26%20Artificial%20Intelligence%29/Mini-Project/sc1015_project/What_do_terrorists_really_want_.ipynb#ch0000110?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Visualisation libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Map stuff\n",
    "# import folium\n",
    "# from folium.plugins import MarkerCluster\n",
    "\n",
    "# Misc\n",
    "# from collections import Counter\n",
    "# sns.set()\n",
    "# %matplotlib inline\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqCYKt2AVjsd"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF8iTItzG2ed"
   },
   "source": [
    "Out of all of the fields that's given to us in the dataset, we would like to take a deeper look into 2 relevant text fields: \"summary\" and \"motive\".\n",
    "\n",
    "According to the GTD Codebook, the **\"summary\"** column gives us an extremely brief narrative summary of the incident which follows the 5W1H (Who,What,When,Where,Why,How) guidelines.\n",
    "\n",
    "Whereas the **\"motive\"** field contains an explicit mention in the official reports. There might be general information about the political, social, or economic situation at the time of attack if it was determined by the researchers to have an impact on the motivation of the incident.\n",
    "\n",
    "Additionally, it is to be noted that these 2 fields were only implemented starting from the year of 1998. Hence, in order to run our data on more valuable data, we will be taking only the events after 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgGEdd7aT6Tk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# GTD Dataset from 1970 - 2019\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/NTU/Sem 1.2/SC1015/SC1015 Mini-Project/globalterrorismdb_0221dist.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_all\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m df_all\u001b[38;5;241m.\u001b[39mto_pickle(file_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# GTD Dataset from 1970 - 2019\n",
    "df_all = pd.read_excel(\"/content/drive/MyDrive/NTU/Sem 1.2/SC1015/SC1015 Mini-Project/globalterrorismdb_0221dist.xlsx\")\n",
    "file_name = 'df_all'\n",
    "df_all.to_pickle(file_name)  # where to save it, usually as a .pkl\n",
    "# df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QgcEfstsLzN"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLpXyokMNp8r"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(file_name)\n",
    "\n",
    "# Drop rows that are before the year 1998\n",
    "df.drop(df[df['iyear'] < 1998].index, inplace=True)\n",
    "\n",
    "# Drop columns that are not needed\n",
    "df.drop(df.columns.difference(['summary', 'motive']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5WVs--xyIoN"
   },
   "outputs": [],
   "source": [
    "# Creating data into an excel file\n",
    "df.to_excel('filename1.xlsx', sheet_name = 'New_Sheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QwR23kDb1wO"
   },
   "outputs": [],
   "source": [
    "# Drop rows with NAN for motive\n",
    "df.dropna(subset = ['motive'], inplace=True)\n",
    "df = df[df[\"motive\"].str.contains(\"Unknown\")==False]\n",
    "df = df[df['motive'] != 'The specific motive for the attack is unknown.']\n",
    "# df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCugkJh9K5Z8"
   },
   "source": [
    "Doing some research beforehand, we understand that we would have to use NLP to help us to reach a conclusion to this question. We think that being able to categorise the words being used in the \"summary\" and \"motive\" fields would help us to better understand the motives of the terrorists.\n",
    "\n",
    "The methods that we could try, include:\n",
    "*   **Topic Modelling**<br>\n",
    "A science that requires both art and science to identify and quantify the mic of topics within a document. Topic Modelling is used when we have a set of text documents that we would like to find out about the different topics that they cover and then group then by these topics. Two Analysis that we could try here:\n",
    "  *   Latent Semantic Analysis (LSA)<br>\n",
    "  This is like Naive Bayes, it is based on the word frequencies of the dataset. The general idea is that the algorithm will count the frequency of the word and group it together with the.\n",
    "  *   Latent Dirichlet Allocation (LDA)<br>\n",
    "  This has a fixed set of topics, we define each topiv to be represented by a set of words. LDA simply tries to map all the words to the topics (in some sort of a backward motion).\n",
    "\n",
    "*   **Topic Classification**<br>\n",
    "A note that this ML algorithm is supervised. Topic Modelling is unsupervised.\n",
    "  *   Empirical Topic Classification (ETC)<br>\n",
    "That combines NLP methods together with human instuition to identity the word features that result in a more meaningful identification of the terrorists' motive categories.\n",
    "\n",
    "To give some hindsight, some of the perpertrator's motives could include retaliation, intimidation, causing instability or to raise contempt — despise a certain community.\n",
    "\n",
    "References:<br>\n",
    "https://www.mdpi.com/2076-0760/11/1/23#<br>\n",
    "https://monkeylearn.com/topic-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wUmNRj8S6YW"
   },
   "source": [
    "# Step 1: Dealing with Motive first\n",
    "\n",
    "This process would involve:\n",
    "<!-- ![picture](https://drive.google.com/uc?export=view&id=1r-rjElUan2DorRG2gUNEGuKzZg399PTi) -->\n",
    "\n",
    "References:<br>\n",
    "https://towardsdatascience.com/text-classification-supervised-unsupervised-learning-approaches-9fd5e01a036<br>\n",
    "pyLDAvis: https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCpj28koZtmS"
   },
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "*   Change the text into lowercase\n",
    "*   Remove all punctuations\n",
    "*   Tokenization<br>\n",
    "Split the text into sentences and the sentences into words.=\n",
    "*   All stopwords are removed.\n",
    "*   Words are lemmatized<br>\n",
    "Where the words written in third person will be changed to first person. Verbs that are in past and future tenses are changed to the present.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB-WJCHCIUTo",
    "outputId": "bdd0f599-a008-4c5a-b93f-871ba368ad53"
   },
   "outputs": [],
   "source": [
    "# Converting all of the strings into lowercase\n",
    "df['motive'] = df['motive'].str.lower()\n",
    "\n",
    "# Removing punctuation\n",
    "df['motive'] = df['motive'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "# Removing digits\n",
    "df['motive'] = df['motive'].str.replace('\\d+', '')\n",
    "\n",
    "df['motive'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cm3GjSvOZbXV",
    "outputId": "69bd3c29-7e43-459b-c226-57a3cb792e09"
   },
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop = stopwords.words('english')\n",
    "newStopWords = ['unknown','however','specific','motive','sources','noted','reported','related','victim',\\\n",
    "                'attack','targeted','speculated','claimed','responsibility','incident','stated','scheduled',\\\n",
    "                'larger','part','suspected','carried','accused','may','january','february','march','april','june',\\\n",
    "                'july','august','september','october','november','december','people','believed','meant','considered']\n",
    "stop.extend(newStopWords)\n",
    "df['motive'] = df['motive'].apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "df['motive'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eDnuU0Qnivs"
   },
   "outputs": [],
   "source": [
    "# Tokenization — splitting the text into sentences and sentences into words\n",
    "# df['motive'].apply(word_tokenize)\n",
    "\n",
    "# df['motive'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhVHSBU6bEc4",
    "outputId": "90120bc6-3f18-4a28-9fc8-fe1eea299ca9"
   },
   "outputs": [],
   "source": [
    "# Initialise the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word - Group together different forms of the same word (e.g Running == Run)\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "df['motive'] = df['motive'].apply(lemmatize_text)\n",
    "print(df['motive'].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9oK5gBMzro3"
   },
   "outputs": [],
   "source": [
    "# Splitting the Dataset - Wouldn't need to split dataset for this unsupervised learning model\n",
    "# X_train, X_test = train_test_split(df['motive'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IZzBBSWrAXw"
   },
   "outputs": [],
   "source": [
    "# Creating data into an excel file\n",
    "df.to_excel('filename.xlsx', sheet_name = 'New_sheet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB-rl1fDin6R"
   },
   "source": [
    "## Bag of Words on the Dataset\n",
    "A popular technique for developing sentiment analysis models is to use a bag-of-words model that transforms documents into vectors where each word in the document is assigned a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZ-RbkWaieb-",
    "outputId": "24d2d9c9-d737-4d7b-9b46-a91ccf501c43"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from the df['motive'] containing the number of times a word appears in the training set.\n",
    "dictionary = gensim.corpora.Dictionary(df['motive'])\n",
    "\n",
    "# Print words that are in the top 10\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRJbF3HXjete"
   },
   "outputs": [],
   "source": [
    "# For each row, we will create another dictionary to document the number of words and the number of times that each words appear\n",
    "bagofwords = [dictionary.doc2bow(doc) for doc in df['motive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbSEpsI1priT",
    "outputId": "fde4b17a-9cbd-401f-b89f-413896ec70ab"
   },
   "outputs": [],
   "source": [
    "# Printing of the 10th row (Preview)\n",
    "bagofwords[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIJd_ZIjqodP"
   },
   "source": [
    "## Running LDA using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWUH3Qj4qoRq",
    "outputId": "a394b90b-c0de-4187-ed13-99ffce25ccbe"
   },
   "outputs": [],
   "source": [
    "# Train our LDA model with the gensim models LDAMulticore\n",
    "# num_topics: the number of requested latent topics to be extracted from the training corpus. We will stick to 6 for now.\n",
    "lda_bow = gensim.models.LdaMulticore(bagofwords, num_topics=6, id2word=dictionary, workers=3)\n",
    "\n",
    "for idx, topic in lda_bow.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "id": "wRcWmmnm5B0E",
    "outputId": "d79a022d-677d-4baa-e2fb-52ecf2e42dc0"
   },
   "outputs": [],
   "source": [
    "# Importing pyLDAvis module for visualisation\n",
    "# !pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda_bow, bagofwords, dictionary, sort_topics=True)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJ0blVULTCg2"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'lda_bow.sav'\n",
    "pickle.dump(lda_bow, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cWYiiRqkv2e"
   },
   "source": [
    "## Running LDA using TFIDF\n",
    "\"In information retrieval, tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\"<br>\n",
    "\n",
    "[Taken from Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhK7Wdm6kuwq"
   },
   "outputs": [],
   "source": [
    "# Creating the tf-idf model\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "\n",
    "tfidf = models.TfidfModel(bagofwords)\n",
    "corpus_tfidf = tfidf[bagofwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVDRgjWWrmCR",
    "outputId": "03ccb869-0b3b-4414-b7cc-00a5b42d463e"
   },
   "outputs": [],
   "source": [
    "lda_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=6, id2word=dictionary, workers=3)\n",
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "id": "9pUYja6N0qEd",
    "outputId": "58dae374-a8f0-45f0-ec68-d2afec8b20b9"
   },
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.gensim_models.prepare(lda_tfidf, corpus_tfidf, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extCMpAOTRW_"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'lda_tfidf.sav'\n",
    "pickle.dump(lda_tfidf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCd5GkP5x5ij"
   },
   "source": [
    "BoW and TFIDF are simply based on the frequency of the words found. However, one of the drawbacks of using this method is the understanding of the context. This is where Word Embedding techniques like Word2Vec, Continuous Bag of Words (CBOW), Skipgram would come in.\n",
    "\n",
    "For the sake of the simplicity of this model, we will not delve into such algorithm but rather just understand that there are many other ways to improve the analysis of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-F7Q_TrGnQv"
   },
   "source": [
    "## Name the topics obtained using Google [Not working]\n",
    "It gave me some results before though. I think maybe Google had blocked my IP from runnng the cell too many times. But VPN doesn't work either. So I think they blacklisted my account.\n",
    "\n",
    "Update, it allowed for me to run again the next day. So I assume that I just simply can't run too many times in a short span of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIDjXUDPBKqz"
   },
   "outputs": [],
   "source": [
    "# !pip install cssselect\n",
    "\n",
    "# Thank you to Sam H. who shared this on https://stackoverflow.com/questions/43985683/automatic-labeling-of-lda-generated-topics\n",
    "from urllib.parse import urlencode, urlparse, parse_qs\n",
    "from lxml.html import fromstring\n",
    "from requests import get\n",
    "from collections import Counter\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_srp_text(search_term):\n",
    "    raw = get(f\"https://www.google.com/search?q={search_term}\").text\n",
    "    page = fromstring(raw)\n",
    "\n",
    "    blob = \"\"\n",
    "\n",
    "    for result in page.cssselect(\"a\"):\n",
    "        for res in result.findall(\"div\"):\n",
    "            blob += ' '\n",
    "            blob += res.text if res.text else \" \"\n",
    "            blob += ' '\n",
    "    return blob\n",
    "\n",
    "def blob_cleaner(blob):\n",
    "    clean_blob = blob.replace(r'[\\/,\\(,\\),\\:,_,-,\\-]', ' ')\n",
    "    return ''.join(e for e in blob if e.isalnum() or e.isspace())\n",
    "\n",
    "def get_name_from_srp_blob(clean_blob):\n",
    "    blob_tokens = list(filter(bool, map(lambda x: x if len(x) > 2 else '', clean_blob.split(' '))))\n",
    "    print(blob_tokens)\n",
    "    c = Counter(blob_tokens)\n",
    "    most_common = c.most_common(10)\n",
    "\n",
    "    name = f\"{most_common[0][0]}-{most_common[1][0]}\"\n",
    "    return name\n",
    "\n",
    "pipeline = lambda x: get_name_from_srp_blob(blob_cleaner(get_srp_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpALjj2ZJIQc",
    "outputId": "8414b85f-49cd-46b2-8f30-70a611847615"
   },
   "outputs": [],
   "source": [
    "# topic_dict = {'Topic_' + str(i): [token for token, score in lda_bow.show_topic(i, topn=10)] for i in range(0, lda_bow.num_topics)}\n",
    "# # print(topic_dict)\n",
    "# for key in topic_dict:\n",
    "#     joined = \" \".join(topic_dict[key])\n",
    "#     # print(joined)\n",
    "#     name = pipeline(joined)\n",
    "#     print(name)\n",
    "\n",
    "topic_terms = \"delivery area mile option partner traffic hub thanks city way\"\n",
    "name = pipeline(topic_terms)\n",
    "print(name)\n",
    "\n",
    "# topic_terms = \"package address time customer apartment delivery number item support door\"\n",
    "# name = pipeline(topic_terms)\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDkZnpEQvNAP"
   },
   "source": [
    "Results obtained don't really make sense.\n",
    "\n",
    "topic_terms = \"delivery area mile option partner traffic hub thanks city way\". Gives me ['mediumcom', 'sidewalktalk', 'thefutureoflastmiledeliveryhasarrived', 'deptswashingtonedu', 'sctlctr', 'newsevents', 'inthenews', 'futurelastmil', 'wwwcapgeminicom', 'ReportDigitalLastMileDeliveryChallenge1', 'wwwmckinseycom', 'travellogisticsandinfrastructure', 'ourinsights', 'wwwmckinseycom', 'industries', 'ourinsights', 'orderingintherapidevo', 'wwwbcgcom', 'publications', 'solvingthepackagedeliverysystemprobl', 'gigglefinancecom', 'whichfooddeliveryservicepaysthemost', 'wwwgovtmonitorcom', 'page', 'View', 'all', 'wwworegonlivecom', 'business', '202009', 'amazonplans1000smalldel']\n",
    "wwwmckinseycom-ourinsights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePs-Jg2PPiL2"
   },
   "source": [
    "Since there is no specific way or recommended way to label the topic terms obtained. We are going to do a little screening here and realise that the top few vocab being used do make some sense. Hence, in the following lines of code, we are going to assume and categorise the motive column into these 6 groups:\n",
    "\n",
    "We will be using the topic breakdown from lda_bow, because they seem to have a more balanced categorisation.\n",
    "\n",
    "*   Retaliation\n",
    "*   Religion\n",
    "*   Extortion\n",
    "*   Fear\n",
    "*   Political\n",
    "*   Violence\n",
    "\n",
    "Referenced: https://medcraveonline.com/FRCIJ/motivation-leading-to-radicalization-in-terrorists.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af9LVZ39WAN2"
   },
   "source": [
    "## Evaluation of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPJ2gQszWzYf"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary to hold the catergories\n",
    "motive_dict = {\n",
    "    '0': \"Retaliation\",\n",
    "    '1': \"Religion\",\n",
    "    '2': \"Extortion\",\n",
    "    '3': \"Fear\",\n",
    "    '4': \"Political\",\n",
    "    '5': \"Violence\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3i7c5AsRrR7",
    "outputId": "f4834a61-422a-41d7-d8a9-a6ebbf4dd90d"
   },
   "outputs": [],
   "source": [
    "# Extracting Topics from Copus\n",
    "print(lda_bow.print_topics(num_topics=6, num_words=5))\n",
    "print(lda_tfidf.print_topics(num_topics=6, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBm4Lov_ToOL"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61198009/classify-text-with-gensim-lda-model\n",
    "count = 1\n",
    "stop = 0\n",
    "motiveCat=[]\n",
    "for line in df['motive']: # where each line in the document is its own sentence for simplicity\n",
    "    # print('\\nSentence: ', line)\n",
    "    # line = line.split()\n",
    "    line_bow = dictionary.doc2bow(line)\n",
    "    doc_lda = lda_bow[line_bow]\n",
    "    # print(doc_lda)\n",
    "    # print(max(doc_lda,key=lambda x:x[1])[0])\n",
    "    # print('\\nLine ' + str(count) + ' assigned to Topic ' + motive_dict[str(max(doc_lda)[0])] + ' with ' + str(round(max(doc_lda)[1]*100,2)) + ' probability!')\n",
    "    count += 1\n",
    "    motiveCat.append(motive_dict[str(max(doc_lda,key=lambda x:x[1])[0])])\n",
    "    # if(str(max(doc_lda)[0])=='1'):\n",
    "    #     print('\\nSentence: ', line)\n",
    "    #     print('\\nLine ' + str(count) + ' assigned to Topic ' + motive_dict[str(max(doc_lda)[0])] + ' with ' + str(round(max(doc_lda)[1]*100,2)) + ' probability!')\n",
    "    # stop+=1\n",
    "    # if(stop==100):\n",
    "    #     break\n",
    "    \n",
    "df['motiveCat1'] = motiveCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVOs__qhX1s5",
    "outputId": "29455b32-ee97-46b3-82f4-eb493cbefb52"
   },
   "outputs": [],
   "source": [
    "df['motiveCat1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSb5NWQGMPLZ"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61198009/classify-text-with-gensim-lda-model\n",
    "count = 1\n",
    "stop = 0\n",
    "motiveCat=[]\n",
    "for line in df['motive']: # where each line in the document is its own sentence for simplicity\n",
    "    # print('\\nSentence: ', line)\n",
    "    # line = line.split()\n",
    "    line_bow = dictionary.doc2bow(line)\n",
    "    doc_lda = lda_tfidf[line_bow]\n",
    "    # print(doc_lda)\n",
    "    # print(max(doc_lda,key=lambda x:x[1])[0])\n",
    "    # print('\\nLine ' + str(count) + ' assigned to Topic ' + motive_dict[str(max(doc_lda)[0])] + ' with ' + str(round(max(doc_lda)[1]*100,2)) + ' probability!')\n",
    "    count += 1\n",
    "    motiveCat.append(motive_dict[str(max(doc_lda,key=lambda x:x[1])[0])])\n",
    "    # if(str(max(doc_lda)[0])=='1'):\n",
    "    #     print('\\nSentence: ', line)\n",
    "    #     print('\\nLine ' + str(count) + ' assigned to Topic ' + motive_dict[str(max(doc_lda)[0])] + ' with ' + str(round(max(doc_lda)[1]*100,2)) + ' probability!')\n",
    "    # stop+=1\n",
    "    # if(stop==100):\n",
    "    #     break\n",
    "    \n",
    "df['motiveCat2'] = motiveCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zon_NqdiMXbc",
    "outputId": "4dca78ee-db7e-4e46-c309-37f8bd2145ea"
   },
   "outputs": [],
   "source": [
    "df['motiveCat2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buchnkFw8fV9"
   },
   "source": [
    "# Step 2: Dealing with Summary (Using the LDA models)\n",
    "We will be using the previous lda_bow to categorise the motives for each row, we will using each summary with the motive categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kkUwbC6opBV"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkpocjzxorLV",
    "outputId": "f8feee57-4097-4b0e-f59a-bf90a8316047"
   },
   "outputs": [],
   "source": [
    "# Converting all of the strings into lowercase\n",
    "df['summary'] = df['summary'].str.lower()\n",
    "\n",
    "# Removing punctuation\n",
    "df['summary'] = df['summary'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "# Removing digits\n",
    "df['summary'] = df['summary'].str.replace('\\d+', '')\n",
    "\n",
    "df['summary'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cy3MkuSrAQs"
   },
   "outputs": [],
   "source": [
    "# for i, row in df.iterrows():\n",
    "#     print(row['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ik-31gbV8e2M",
    "outputId": "fd288232-fbd2-4924-a40e-36e88013b27b"
   },
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop = stopwords.words('english')\n",
    "newStopWords = ['unknown','however','specific','motive','sources','noted','reported','related','victim',\\\n",
    "                'attack','targeted','speculated','claimed','responsibility','incident','stated','scheduled',\\\n",
    "                'larger','part','suspected','carried','accused','may','january','february','march','april','june',\\\n",
    "                'july','august','september','october','november','december','people','believed','meant','considered']\n",
    "stop.extend(newStopWords)\n",
    "\n",
    "df['summary'] = df['summary'].apply(lambda x: [word for word in x.split() if word not in (stop)])\n",
    "df['summary'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxmI7Anto_Vg",
    "outputId": "f89533ad-6f4f-4457-9a8e-cba0610624a8"
   },
   "outputs": [],
   "source": [
    "# Initialise the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word - Group together different forms of the same word (e.g Running == Run)\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "df['summary'] = df['summary'].apply(lemmatize_text)\n",
    "print(df['summary'].head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUhqDaeQpGM8"
   },
   "source": [
    "## Bag of Words on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfTcgRwTpLUf",
    "outputId": "62989e54-a189-4177-b66d-7d54da44e920"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from the df['motive'] containing the number of times a word appears in the training set.\n",
    "dictionary = gensim.corpora.Dictionary(df['summary'])\n",
    "\n",
    "# Print words that are in the top 10\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzjFqxp3pNFO"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# For each row, we will create another dictionary to document the number of words and the number of times that each words appear\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True)\n",
    "\n",
    "arr = []\n",
    "for i in df['summary']:\n",
    "    arr.append(' '.join(i))\n",
    "df['summary'] = arr\n",
    "bagofwords = vectorizer.fit_transform(df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HqaOq-40xAD",
    "outputId": "1911bdae-c378-463a-b151-f5531e2a55a5"
   },
   "outputs": [],
   "source": [
    "# df[\"summary\"]= df[\"summary\"].str.join(\" \")\n",
    "X = bagofwords\n",
    "y = df['motiveCat1'].values\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "print(X[:1])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ty1ppfGT22GJ"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into Training set and Test set \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE8v91zBADcT"
   },
   "source": [
    "## KernelSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlAc82J61Qh0",
    "outputId": "3b9f24fa-a172-4141-a16e-143b402c52bb"
   },
   "outputs": [],
   "source": [
    "# Fitting Kernel SVM to the Training set \n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel = 'rbf', random_state = 0) \n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sebS_ZIKBn5B"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '2_kernelSVM.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJGXVSrl1Tfn"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creating a definition for the eval part\n",
    "def eval():\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Making the Classification Report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Using the ROC AUC score matrix\n",
    "    # roc_auc_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRu5FJP_DV6t",
    "outputId": "0267b438-3c58-4a1b-a3b2-2df83c48910e"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBiog0VwAFMa"
   },
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHyKkATrAkJc",
    "outputId": "b932a67c-bd63-40c2-c01b-4abfb3cfe2b1"
   },
   "outputs": [],
   "source": [
    "# Fitting Log Reg to the Training set \n",
    "model = LogisticRegression(solver=\"sag\", max_iter=400)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqEF-r9hB251"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '2_logreg.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEcmxhrMAkLP",
    "outputId": "45534b7c-fde4-4dfa-f1bb-eeffb68e0ae3"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtinxtmsAKM5"
   },
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idXXHdjGD_Yn",
    "outputId": "9f32f85a-ee42-4f81-9f7a-e10cb9aca9a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6ekYt5zEhTu"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '3_sgd.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCpOKAi_EkPR",
    "outputId": "01828cfe-6e9f-4a2f-dfd1-89b896a08940"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuB1xWPzAMxH"
   },
   "source": [
    "## Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h93SqWShEr4N"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-23YV2H_E_t_"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '4_dt.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNcA5kRGFBnL",
    "outputId": "20b6ad1c-2ad2-44fc-e361-c25bb12c474b"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fd5vAHNGFKn0"
   },
   "outputs": [],
   "source": [
    "# Visualizing Decision Trees\n",
    "# !pip install six\n",
    "# from six import StringIO  \n",
    "# from IPython.display import Image  \n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "\n",
    "# feature_cols = ['Exortion', 'Fear', 'Political', 'Religion','Retaliation','Violence']\n",
    "# dot_data = StringIO()\n",
    "# export_graphviz(model, out_file=dot_data,  \n",
    "#                 filled=True, rounded=True,\n",
    "#                 special_characters=True, feature_names = feature_cols, class_names=['0','1'])\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# graph.write_png('diabetes.png')\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxjMo1wAQOQ"
   },
   "source": [
    "## Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNU45o_fFj0p",
    "outputId": "db91cd04-8ad9-408e-e9da-2c76793dd90b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHe3amJ7Gix5"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '5_rf.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqFm7c2yGmZJ",
    "outputId": "53114329-63e9-4189-88c8-eb508d177db2"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuq9DKVdopZx"
   },
   "source": [
    "Interesting, that Random Forest also gives us a good accuracy here and in our previous question. Beating out the rest of the models that we have trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI7JAt2aAYqX"
   },
   "source": [
    "## k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ras0wYfKATig",
    "outputId": "5031f924-bf07-47c1-81c4-790e1092b165"
   },
   "outputs": [],
   "source": [
    "model = KNN(n_neighbors=7)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYKarEZ6Gu-m"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '6_knn.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFvVqCZQGxzr",
    "outputId": "97ae6e75-9eb3-4fca-a103-44aea2ad5a6c"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICpxQxFXAUJ9"
   },
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf4R29o5AbGV",
    "outputId": "3db978d1-9017-493f-9a20-32439a9fc912"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EYvCKXqHYqd"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '7_adaBoost.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bba_4J_AHboT",
    "outputId": "67072bf4-cd17-4e64-82a1-be69584580bb"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZxWoOj7Ablj"
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwKVjGRAHepQ",
    "outputId": "e80a6221-4513-4741-8726-ac0e7e4be998"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pomoQS6EHnw8"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '8_gradientBoosting.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eF3aEHKYHrdG",
    "outputId": "55c4f720-d22b-4014-988b-c4f237cb19dd"
   },
   "outputs": [],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6Z1Xorhn0fa"
   },
   "source": [
    "Gradient boosting and ADA Boosting are known to some of Ensemble Learning methods, and a boosting method. It is used to combine several weak \"learners\" into a stronger model. The concept of boosting is quite interesting because it tries to fit a new predictor into the errors that were made by models before.\n",
    "\n",
    "Adaboost apparently gave us a lower accuracy 0.40 at predicting the motive categories.\n",
    "\n",
    "GB obtaining an accuracy of 0.49 indicates that it was no better than running the previous models (without Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U89EbpviIKli"
   },
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htdvz4yZ1VJL",
    "outputId": "816f5fea-82f0-412c-846f-a1b94761e32d"
   },
   "outputs": [],
   "source": [
    "# Applying k-Fold Cross Validation - not helpful right now\n",
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icybAq_gnM93"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = '9_kfold.sav'\n",
    "pickle.dump(accuracies, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTHje6pfhnM6",
    "outputId": "b1e2c2ca-bca0-4f4b-9bd1-f8591d2b1693"
   },
   "outputs": [],
   "source": [
    "print(accuracies.mean())\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIm5hjRXmtyA"
   },
   "source": [
    "Using the K-Fold Cross Validation should improve the model in general, however in this case, we would attribute it to a case of a little over-fitting. The other models that were executed, had also an average accuracy of 0.49. Hence we can conclude that executing K-Fold Cross Validation does not help us in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3G85-1GHx2d"
   },
   "source": [
    "# Step 3: Evaluation\n",
    "Summing everything up, we have used LDA to determine the motive categories and obtained 6 of them that we think would be most suitable to represent the topic labels.\n",
    "\n",
    "*   Retaliation\n",
    "*   Religion\n",
    "*   Extortion\n",
    "*   Fear\n",
    "*   Political\n",
    "*   Violence\n",
    "\n",
    "The above are the reasons and the main goals of the terrorists for initiating such attacks.\n",
    "\n",
    "Taking a look at the perfomance metrices for each model. We have learnt from doing the previous question \"What makes a successful terrorist attack?\" that the accuracy cannot entirely be depended on:\n",
    "\n",
    "*   Confusion Matrix - Great for visualisation (Based on TP,TN,FN,FP)\n",
    "*   Accuracy - Not a very good indicator. Most commonly used, the number of correct predictions made as a ratio of all predictions\n",
    "*   Precision - TP/(TP+FP). This is the measure of precision.\n",
    "*   Recall - TP/(TP+FN). This is the measure of precision.\n",
    "*   F1-score - This is the measure of precision and recall. Taking FP and FN into account.\n",
    "*   ROC-AUC score - AUC represents an average indicator of performance across all the possible classification thresholds.\n",
    "\n",
    "Reference: <br>\n",
    "Performance Metrics: https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m03_6B0TpQVv"
   },
   "source": [
    "## Conclusion\n",
    "We also understand that through this process, we have significantly cut down on alot of data points. Going to columns, and after preprocessing the data for NLP, the once 200k data points in it's glory is reduced to around 20k of them. However, it is still significant enough for us to draw analysis.\n",
    "\n",
    "Now to finally answer the question: \"What do terrorists really want?\". We can see that terrorists usually attack civilians to maximise their political gains (as we can see the political category having the highest number of datapoints = 966). Perhaps it's to make a statement and coming from a place of wanting to be heard. Although the models created were not exactly extremely accurate when determining the categories, being able to use LDA to determine the most common frequencies of words really helps us to understand the motives better, and hence group them under 6 topic labels. \n",
    "\n",
    "One of the ways that we thought could help in countering such terrorist attacks is to dimininish their benefits from the attack. Meaning that since we can know of their aims beforehand, we would be able to strategise against their goals and void the attack, hopefully stopping it in the early planning stages.\n",
    "\n",
    "Originally, we wanted to use the models to try and help predict certain keywords that appear, like their country, situation, some background info that was obtained before the attacks was executed. From there, being able to predict what the the terrorists want before them stating it to us."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "What do terrorists really want?.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
